{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/byluca/llm-from-scratch/blob/main/llm_from_scratch.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QyqbEOc3CwmM"
      },
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sfmLUMVICySe"
      },
      "source": [
        "### TOKENIZER USING BYTE PAIR ENCODING (BPE)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "GUqRXVjsLIxB"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RlbGJrayDFTx",
        "outputId": "de2110b3-caf0-461a-ee33-b9861e2b0f38"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: tiktoken in /usr/local/lib/python3.11/dist-packages (0.10.0)\n",
            "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.11/dist-packages (from tiktoken) (2024.11.6)\n",
            "Requirement already satisfied: requests>=2.26.0 in /usr/local/lib/python3.11/dist-packages (from tiktoken) (2.32.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.26.0->tiktoken) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.26.0->tiktoken) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.26.0->tiktoken) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.26.0->tiktoken) (2025.8.3)\n"
          ]
        }
      ],
      "source": [
        "!pip3 install tiktoken"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "file_path = '/content/drive/MyDrive/Colab Notebooks/montecristo.txt'"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rKMyzyElLJsU",
        "outputId": "d00378cd-693e-4e27-d901-9a8c0f1937c0"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "with open(file_path, 'r', encoding='utf-8') as f:\n",
        "    raw_text = f.read()\n",
        "\n",
        "print(f\"Lunghezza del testo: {len(raw_text)} caratteri\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FRJvER0XLXDb",
        "outputId": "77826de5-75c7-4a8f-e172-f6722da6e768"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Lunghezza del testo: 2699512 caratteri\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### IMPLEMENTING A DATA LOADER\n",
        "\n"
      ],
      "metadata": {
        "id": "QqyGs11nkjmr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import Dataset, DataLoader\n",
        "\n",
        "\n",
        "class GPTDatasetV1(Dataset):\n",
        "    def __init__(self, txt, tokenizer, max_length, stride):\n",
        "        self.input_ids = []    # lista per gli input\n",
        "        self.target_ids = []   # lista per i target\n",
        "\n",
        "        # Tokenizza tutto il testo\n",
        "        token_ids = tokenizer.encode(txt, allowed_special={\"<|endoftext|>\"})\n",
        "\n",
        "        # Scorri il testo con una finestra mobile per creare sequenze sovrapposte\n",
        "        for i in range(0, len(token_ids) - max_length, stride):\n",
        "            input_chunk = token_ids[i:i + max_length]            # sequenza input\n",
        "            target_chunk = token_ids[i + 1: i + max_length + 1]  # sequenza target spostata di 1\n",
        "            self.input_ids.append(torch.tensor(input_chunk))     # aggiungi input come tensore\n",
        "            self.target_ids.append(torch.tensor(target_chunk))   # aggiungi target come tensore\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.input_ids)  # numero totale di sequenze\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        return self.input_ids[idx], self.target_ids[idx]  # ritorna input e target per l’indice dato\n"
      ],
      "metadata": {
        "id": "29lIqXkIkmEb"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def create_dataloader_v1(txt, batch_size=4, max_length=256,\n",
        "                         stride=128, shuffle=True, drop_last=True,\n",
        "                         num_workers=0):\n",
        "\n",
        "    # Inizializza il tokenizer GPT-2 per trasformare il testo in token\n",
        "    tokenizer = tiktoken.get_encoding(\"gpt2\")\n",
        "\n",
        "    # Crea il dataset personalizzato usando il testo e il tokenizer\n",
        "    dataset = GPTDatasetV1(txt, tokenizer, max_length, stride)\n",
        "\n",
        "    # Crea il DataLoader per gestire i dati in batch durante l'addestramento\n",
        "    dataloader = DataLoader(\n",
        "        dataset,\n",
        "        batch_size=batch_size,   # numero di sequenze per batch\n",
        "        shuffle=shuffle,         # mescola i dati se True\n",
        "        drop_last=drop_last,     # scarta l'ultimo batch se incompleto\n",
        "        num_workers=num_workers  # numero di processi per caricare i dati in parallelo\n",
        "    )\n",
        "\n",
        "    # Restituisce il DataLoader pronto all'uso\n",
        "    return dataloader\n"
      ],
      "metadata": {
        "id": "FaXNcPwmuELl"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "<div class=\"alert alert-block alert-success\">\n",
        "\n",
        "Testiamo il dataloader con un batch size di 1 per un LLM con una dimensione del contesto di 4.\n",
        "\n",
        "Questo aiuterà a sviluppare un’intuizione su come la classe GPTDatasetV1 e la funzione create_dataloader_v1 lavorano insieme:\n",
        "</div>"
      ],
      "metadata": {
        "id": "3vQaZGFBut5L"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "with open(file_path, \"r\", encoding=\"utf-8\") as f:\n",
        "    raw_text = f.read()\n"
      ],
      "metadata": {
        "id": "Z1lmD1CRuyVF"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "<div class=\"alert alert-block alert-info\">\n",
        "\n",
        "Converti il dataloader in un iteratore Python per ottenere la prossima voce usando la funzione built-in next() di Python.\n",
        "</div>"
      ],
      "metadata": {
        "id": "2q438CWvvAwX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import tiktoken\n",
        "\n",
        "# Stampa la versione di PyTorch installata\n",
        "print(\"PyTorch version:\", torch.__version__)\n",
        "\n",
        "# Crea un DataLoader dal testo raw_text con batch_size=1, sequenze di lunghezza 4, stride 1, senza mescolare i dati\n",
        "dataloader = create_dataloader_v1(\n",
        "    raw_text, batch_size=1, max_length=4, stride=1, shuffle=False\n",
        ")\n",
        "\n",
        "# Trasforma il DataLoader in un iteratore Python per poter usare next()\n",
        "data_iter = iter(dataloader)\n",
        "\n",
        "# Prende il primo batch dall'iteratore\n",
        "first_batch = next(data_iter)\n",
        "\n",
        "# Stampa il primo batch (input e target)\n",
        "print(first_batch)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_0xGVSwUvB-c",
        "outputId": "c2b19d18-218b-45a6-fde0-00f564aef1b7"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "PyTorch version: 2.6.0+cu124\n",
            "[tensor([[  171,   119,   123, 33666]]), tensor([[  119,   123, 33666,  2579]])]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "<div class=\"alert alert-block alert-warning\">\n",
        "\n",
        "La variabile first_batch contiene due tensori: il primo tensore memorizza gli ID dei token di input,\n",
        "e il secondo tensore memorizza gli ID dei token target.\n",
        "\n",
        "Dato che max_length è impostato a 4, ciascuno dei due tensori contiene 4 ID di token.\n",
        "\n",
        "Nota che una dimensione di input pari a 4 è relativamente piccola ed è stata scelta solo a scopo illustrativo.\n",
        "È comune addestrare LLM con dimensioni di input di almeno 256.\n",
        "</div>"
      ],
      "metadata": {
        "id": "AUIr6iM6wpMU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<div class=\"alert alert-block alert-success\">\n",
        "\n",
        "Per illustrare il significato di stride=1, prendiamo un altro batch da questo dataset:\n",
        "\n",
        "</div>\n"
      ],
      "metadata": {
        "id": "N7yx3hJzxM2W"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "second_batch = next(data_iter)\n",
        "print(second_batch)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d6kLZSamwitd",
        "outputId": "7fe9a9a2-7c72-4a01-c110-3f9612914a18"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[tensor([[  119,   123, 33666,  2579]]), tensor([[  123, 33666,  2579,  3158]])]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "<div class=\"alert alert-block alert-warning\">\n",
        "\n",
        "Se confrontiamo il primo batch con il secondo, possiamo vedere che gli ID dei token del secondo batch sono spostati di una posizione rispetto al primo batch.\n",
        "\n",
        "Per esempio, il secondo ID nell’input del primo batch è 123, che è il primo ID nell’input del secondo batch.\n",
        "\n",
        "Il parametro stride determina di quante posizioni gli input si spostano da un batch all’altro, imitando un approccio a finestra mobile.\n",
        "</div>"
      ],
      "metadata": {
        "id": "op8N0ITyxof_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<div class=\"alert alert-block alert-warning\">\n",
        "\n",
        "I batch di dimensione 1, come quelli che abbiamo prelevato finora dal dataloader, sono utili a scopo illustrativo.\n",
        "\n",
        "Se hai esperienza precedente con il deep learning, saprai che batch di piccole dimensioni richiedono meno memoria durante l’addestramento, ma portano a aggiornamenti del modello più rumorosi.\n",
        "\n",
        "Proprio come nel deep learning tradizionale, la dimensione del batch è un compromesso e un iperparametro da sperimentare durante l’addestramento degli LLM.\n",
        "</div>"
      ],
      "metadata": {
        "id": "OYbsvw_Qx1Nl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<div class=\"alert alert-block alert-success\">\n",
        "\n",
        "Prima di passare alle due sezioni finali di questo capitolo, che si concentrano sulla creazione dei vettori di embedding dagli ID dei token, diamo una breve occhiata a come possiamo usare il dataloader per campionare con un batch size maggiore di 1:\n",
        "</div>"
      ],
      "metadata": {
        "id": "ji_mfaUTyHUr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dataloader = create_dataloader_v1(raw_text, batch_size=8, max_length=4, stride=4, shuffle=False)\n",
        "\n",
        "data_iter = iter(dataloader)\n",
        "inputs, targets = next(data_iter)\n",
        "print(\"Inputs:\\n\", inputs)\n",
        "print(\"\\nTargets:\\n\", targets)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oNDeG7Uyxp_M",
        "outputId": "2a16ddbf-62e9-4070-e256-abab97382180"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Inputs:\n",
            " tensor([[  171,   119,   123, 33666],\n",
            "        [ 2579,  3158, 16057,   952],\n",
            "        [ 1248,  1314,  8591,   410],\n",
            "        [  276, 15253,   390,  8466],\n",
            "        [42345,   390,  8466,  4860],\n",
            "        [  544,  1062,   660,  4229],\n",
            "        [  198,   325,  4593,  1000],\n",
            "        [  390,  8466,   299,  1015]])\n",
            "\n",
            "Targets:\n",
            " tensor([[  119,   123, 33666,  2579],\n",
            "        [ 3158, 16057,   952,  1248],\n",
            "        [ 1314,  8591,   410,   276],\n",
            "        [15253,   390,  8466, 42345],\n",
            "        [  390,  8466,  4860,   544],\n",
            "        [ 1062,   660,  4229,   198],\n",
            "        [  325,  4593,  1000,   390],\n",
            "        [ 8466,   299,  1015,   257]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "<div class=\"alert alert-block alert-info\">\n",
        "\n",
        "Nota che aumentiamo lo stride a 4. Questo serve per utilizzare completamente il dataset (non saltiamo nessuna parola) ma anche per evitare sovrapposizioni tra i batch, poiché un’eccessiva sovrapposizione potrebbe portare a un aumento dell’overfitting.\n",
        "</div>"
      ],
      "metadata": {
        "id": "oEgBIe3Eyl_-"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "varajWsLyo2u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "0Y5U4StHyYAo"
      }
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMwTCWM7bVlLn1bv8c3ST/t",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}